{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/01 02:08:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDoubleSafe(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except ValueError:\n",
    "        return str(v) #if it is not a float type return as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and convert the data\n",
    "census_raw = sc.textFile(\"../Data/adult.raw\").map(lambda x : x.split(\",\")).map(lambda x : [toDoubleSafe(y) for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[39.0,\n",
       " ' State-gov',\n",
       " 77516.0,\n",
       " ' Bachelors',\n",
       " ' Never-married',\n",
       " ' Adm-clerical',\n",
       " ' Not-in-family',\n",
       " ' White',\n",
       " ' Male',\n",
       " 2174.0,\n",
       " 0.0,\n",
       " 40.0,\n",
       " ' United-States',\n",
       " ' <=50K']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_raw.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the RDD to DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "adultschema = StructType([\n",
    "    StructField(\"age\",DoubleType(),True),\n",
    "    StructField(\"workclass\",StringType(),True),\n",
    "    StructField(\"fnlwgt\",DoubleType(),True),\n",
    "    StructField(\"education\",StringType(),True),\n",
    "    StructField(\"marital_status\",StringType(),True),\n",
    "    StructField(\"occupation\",StringType(),True),\n",
    "    StructField(\"relationship\",StringType(),True),\n",
    "    StructField(\"race\",StringType(),True),\n",
    "    StructField(\"sex\",StringType(),True),\n",
    "    StructField(\"capital_gain\",DoubleType(),True),\n",
    "    StructField(\"capital_loss\",DoubleType(),True),\n",
    "    StructField(\"hours_per_week\",DoubleType(),True),\n",
    "    StructField(\"native_country\",StringType(),True),\n",
    "    StructField(\"income\",StringType(),True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = ss.createDataFrame(census_raw, adultschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "| age|        workclass|  fnlwgt|    education|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|39.0|        State-gov| 77516.0|    Bachelors|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
      "|50.0| Self-emp-not-inc| 83311.0|    Bachelors|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
      "|38.0|          Private|215646.0|      HS-grad|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|53.0|          Private|234721.0|         11th|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|28.0|          Private|338409.0|    Bachelors|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
      "|37.0|          Private|284582.0|      Masters|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|49.0|          Private|160187.0|          9th| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| <=50K|\n",
      "|52.0| Self-emp-not-inc|209642.0|      HS-grad|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  >50K|\n",
      "|31.0|          Private| 45781.0|      Masters|       Never-married|    Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  >50K|\n",
      "|42.0|          Private|159449.0|    Bachelors|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  >50K|\n",
      "|37.0|          Private|280464.0| Some-college|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  >50K|\n",
      "|30.0|        State-gov|141297.0|    Bachelors|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  >50K|\n",
      "|23.0|          Private|122272.0|    Bachelors|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
      "|32.0|          Private|205019.0|   Assoc-acdm|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
      "|40.0|          Private|121772.0|    Assoc-voc|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  >50K|\n",
      "|34.0|          Private|245487.0|      7th-8th|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| <=50K|\n",
      "|25.0| Self-emp-not-inc|176756.0|      HS-grad|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| <=50K|\n",
      "|32.0|          Private|186824.0|      HS-grad|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|38.0|          Private| 28887.0|         11th|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
      "|43.0| Self-emp-not-inc|292175.0|      Masters|            Divorced|   Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  >50K|\n",
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfraw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|     occupation|count|\n",
      "+---------------+-----+\n",
      "| Prof-specialty| 6172|\n",
      "+---------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Missing data imputation - Impute the most common row for \"?\".\n",
    "# workclass : Private, occupation: Prof-specialty, native_country: United-States has missing values\n",
    "dfraw.groupBy('occupation').count().orderBy('count', ascending=False).show(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing data imputation - Impute the most common row for \"?\".\n",
    "dfrawrp = dfraw.replace([\"?\"], [\"Private\"], [\"workclass\"])\n",
    "dfrawrpl = dfrawrp.replace([\"?\"], [\"Prof-specialty\"], [\"occupation\"])\n",
    "dfrawnona = dfrawrpl.replace([\"?\"], [\"United-States\"], [\"native_country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "| age|        workclass|  fnlwgt|    education|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|39.0|        State-gov| 77516.0|    Bachelors|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
      "|50.0| Self-emp-not-inc| 83311.0|    Bachelors|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
      "|38.0|          Private|215646.0|      HS-grad|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|53.0|          Private|234721.0|         11th|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|28.0|          Private|338409.0|    Bachelors|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
      "|37.0|          Private|284582.0|      Masters|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|49.0|          Private|160187.0|          9th| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| <=50K|\n",
      "|52.0| Self-emp-not-inc|209642.0|      HS-grad|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  >50K|\n",
      "|31.0|          Private| 45781.0|      Masters|       Never-married|    Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  >50K|\n",
      "|42.0|          Private|159449.0|    Bachelors|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  >50K|\n",
      "|37.0|          Private|280464.0| Some-college|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  >50K|\n",
      "|30.0|        State-gov|141297.0|    Bachelors|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  >50K|\n",
      "|23.0|          Private|122272.0|    Bachelors|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| <=50K|\n",
      "|32.0|          Private|205019.0|   Assoc-acdm|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
      "|40.0|          Private|121772.0|    Assoc-voc|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  >50K|\n",
      "|34.0|          Private|245487.0|      7th-8th|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| <=50K|\n",
      "|25.0| Self-emp-not-inc|176756.0|      HS-grad|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| <=50K|\n",
      "|32.0|          Private|186824.0|      HS-grad|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "|38.0|          Private| 28887.0|         11th|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| <=50K|\n",
      "|43.0| Self-emp-not-inc|292175.0|      Masters|            Divorced|   Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  >50K|\n",
      "+----+-----------------+--------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfrawnona.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert strings to categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting strings to numeric values\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "def indexStringColumns(df, cols):\n",
    "    newdf = df\n",
    "    \n",
    "    for c in cols:\n",
    "        newdf = StringIndexer(inputCol=c, outputCol=c+\"-num\")\\\n",
    "                    .fit(newdf)\\\n",
    "                    .transform(newdf)\\\n",
    "                    .drop(c).withColumnRenamed(c+\"-num\", c)\n",
    "        \n",
    "        \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "categorical_col = [\"income\", \"sex\", \"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"native_country\"]\n",
    "df_numeric = indexStringColumns(dfrawnona, categorical_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+------------+--------------+------+---+---------+---------+--------------+----------+------------+----+--------------+\n",
      "| age|  fnlwgt|capital_gain|capital_loss|hours_per_week|income|sex|workclass|education|marital_status|occupation|relationship|race|native_country|\n",
      "+----+--------+------------+------------+--------------+------+---+---------+---------+--------------+----------+------------+----+--------------+\n",
      "|39.0| 77516.0|      2174.0|         0.0|          40.0|   0.0|0.0|      4.0|      2.0|           1.0|       3.0|         1.0| 0.0|           0.0|\n",
      "|50.0| 83311.0|         0.0|         0.0|          13.0|   0.0|0.0|      1.0|      2.0|           0.0|       2.0|         0.0| 0.0|           0.0|\n",
      "|38.0|215646.0|         0.0|         0.0|          40.0|   0.0|0.0|      0.0|      0.0|           2.0|       9.0|         1.0| 0.0|           0.0|\n",
      "|53.0|234721.0|         0.0|         0.0|          40.0|   0.0|0.0|      0.0|      5.0|           0.0|       9.0|         0.0| 1.0|           0.0|\n",
      "|28.0|338409.0|         0.0|         0.0|          40.0|   0.0|1.0|      0.0|      2.0|           0.0|       0.0|         4.0| 1.0|           9.0|\n",
      "|37.0|284582.0|         0.0|         0.0|          40.0|   0.0|1.0|      0.0|      3.0|           0.0|       2.0|         4.0| 0.0|           0.0|\n",
      "|49.0|160187.0|         0.0|         0.0|          16.0|   0.0|1.0|      0.0|     10.0|           5.0|       5.0|         1.0| 1.0|          13.0|\n",
      "|52.0|209642.0|         0.0|         0.0|          45.0|   1.0|0.0|      1.0|      0.0|           0.0|       2.0|         0.0| 0.0|           0.0|\n",
      "|31.0| 45781.0|     14084.0|         0.0|          50.0|   1.0|1.0|      0.0|      3.0|           1.0|       0.0|         1.0| 0.0|           0.0|\n",
      "|42.0|159449.0|      5178.0|         0.0|          40.0|   1.0|0.0|      0.0|      2.0|           0.0|       2.0|         0.0| 0.0|           0.0|\n",
      "|37.0|280464.0|         0.0|         0.0|          80.0|   1.0|0.0|      0.0|      1.0|           0.0|       2.0|         0.0| 1.0|           0.0|\n",
      "|30.0|141297.0|         0.0|         0.0|          40.0|   1.0|0.0|      4.0|      2.0|           0.0|       0.0|         0.0| 2.0|           8.0|\n",
      "|23.0|122272.0|         0.0|         0.0|          30.0|   0.0|1.0|      0.0|      2.0|           1.0|       3.0|         2.0| 0.0|           0.0|\n",
      "|32.0|205019.0|         0.0|         0.0|          50.0|   0.0|0.0|      0.0|      6.0|           1.0|       4.0|         1.0| 1.0|           0.0|\n",
      "|40.0|121772.0|         0.0|         0.0|          40.0|   1.0|0.0|      0.0|      4.0|           0.0|       1.0|         0.0| 2.0|           2.0|\n",
      "|34.0|245487.0|         0.0|         0.0|          45.0|   0.0|0.0|      0.0|      8.0|           0.0|       8.0|         0.0| 3.0|           1.0|\n",
      "|25.0|176756.0|         0.0|         0.0|          35.0|   0.0|0.0|      1.0|      0.0|           1.0|      10.0|         2.0| 0.0|           0.0|\n",
      "|32.0|186824.0|         0.0|         0.0|          40.0|   0.0|0.0|      0.0|      0.0|           1.0|       6.0|         3.0| 0.0|           0.0|\n",
      "|38.0| 28887.0|         0.0|         0.0|          50.0|   0.0|0.0|      0.0|      5.0|           0.0|       4.0|         0.0| 0.0|           0.0|\n",
      "|43.0|292175.0|         0.0|         0.0|          45.0|   1.0|1.0|      1.0|      3.0|           2.0|       2.0|         3.0| 0.0|           0.0|\n",
      "+----+--------+------------+------------+--------------+------+---+---------+---------+--------------+----------+------------+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_numeric.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income',\n",
       " 'sex',\n",
       " 'workclass',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'native_country']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols: \n",
    "        ohe = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        ohe_model = ohe.fit(newdf)\n",
    "        \n",
    "        newdf = ohe_model.transform(newdf).drop(c).withColumnRenamed(c+\"-onehot\", c)\n",
    "        \n",
    "    return newdf\n",
    "\n",
    "categorical_col.remove(\"income\")\n",
    "dfhot = oneHotEncodeColumns(df_numeric, categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+------------+--------------+------+-------------+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "| age|  fnlwgt|capital_gain|capital_loss|hours_per_week|income|          sex|    workclass|      education|marital_status|     occupation| relationship|         race| native_country|\n",
      "+----+--------+------------+------------+--------------+------+-------------+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "|39.0| 77516.0|      2174.0|         0.0|          40.0|   0.0|(2,[0],[1.0])|(9,[4],[1.0])| (16,[2],[1.0])| (7,[1],[1.0])| (15,[3],[1.0])|(6,[1],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|50.0| 83311.0|         0.0|         0.0|          13.0|   0.0|(2,[0],[1.0])|(9,[1],[1.0])| (16,[2],[1.0])| (7,[0],[1.0])| (15,[2],[1.0])|(6,[0],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|38.0|215646.0|         0.0|         0.0|          40.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[0],[1.0])| (7,[2],[1.0])| (15,[9],[1.0])|(6,[1],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|53.0|234721.0|         0.0|         0.0|          40.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[5],[1.0])| (7,[0],[1.0])| (15,[9],[1.0])|(6,[0],[1.0])|(5,[1],[1.0])| (42,[0],[1.0])|\n",
      "|28.0|338409.0|         0.0|         0.0|          40.0|   0.0|(2,[1],[1.0])|(9,[0],[1.0])| (16,[2],[1.0])| (7,[0],[1.0])| (15,[0],[1.0])|(6,[4],[1.0])|(5,[1],[1.0])| (42,[9],[1.0])|\n",
      "|37.0|284582.0|         0.0|         0.0|          40.0|   0.0|(2,[1],[1.0])|(9,[0],[1.0])| (16,[3],[1.0])| (7,[0],[1.0])| (15,[2],[1.0])|(6,[4],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|49.0|160187.0|         0.0|         0.0|          16.0|   0.0|(2,[1],[1.0])|(9,[0],[1.0])|(16,[10],[1.0])| (7,[5],[1.0])| (15,[5],[1.0])|(6,[1],[1.0])|(5,[1],[1.0])|(42,[13],[1.0])|\n",
      "|52.0|209642.0|         0.0|         0.0|          45.0|   1.0|(2,[0],[1.0])|(9,[1],[1.0])| (16,[0],[1.0])| (7,[0],[1.0])| (15,[2],[1.0])|(6,[0],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|31.0| 45781.0|     14084.0|         0.0|          50.0|   1.0|(2,[1],[1.0])|(9,[0],[1.0])| (16,[3],[1.0])| (7,[1],[1.0])| (15,[0],[1.0])|(6,[1],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|42.0|159449.0|      5178.0|         0.0|          40.0|   1.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[2],[1.0])| (7,[0],[1.0])| (15,[2],[1.0])|(6,[0],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|37.0|280464.0|         0.0|         0.0|          80.0|   1.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[1],[1.0])| (7,[0],[1.0])| (15,[2],[1.0])|(6,[0],[1.0])|(5,[1],[1.0])| (42,[0],[1.0])|\n",
      "|30.0|141297.0|         0.0|         0.0|          40.0|   1.0|(2,[0],[1.0])|(9,[4],[1.0])| (16,[2],[1.0])| (7,[0],[1.0])| (15,[0],[1.0])|(6,[0],[1.0])|(5,[2],[1.0])| (42,[8],[1.0])|\n",
      "|23.0|122272.0|         0.0|         0.0|          30.0|   0.0|(2,[1],[1.0])|(9,[0],[1.0])| (16,[2],[1.0])| (7,[1],[1.0])| (15,[3],[1.0])|(6,[2],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|32.0|205019.0|         0.0|         0.0|          50.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[6],[1.0])| (7,[1],[1.0])| (15,[4],[1.0])|(6,[1],[1.0])|(5,[1],[1.0])| (42,[0],[1.0])|\n",
      "|40.0|121772.0|         0.0|         0.0|          40.0|   1.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[4],[1.0])| (7,[0],[1.0])| (15,[1],[1.0])|(6,[0],[1.0])|(5,[2],[1.0])| (42,[2],[1.0])|\n",
      "|34.0|245487.0|         0.0|         0.0|          45.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[8],[1.0])| (7,[0],[1.0])| (15,[8],[1.0])|(6,[0],[1.0])|(5,[3],[1.0])| (42,[1],[1.0])|\n",
      "|25.0|176756.0|         0.0|         0.0|          35.0|   0.0|(2,[0],[1.0])|(9,[1],[1.0])| (16,[0],[1.0])| (7,[1],[1.0])|(15,[10],[1.0])|(6,[2],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|32.0|186824.0|         0.0|         0.0|          40.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[0],[1.0])| (7,[1],[1.0])| (15,[6],[1.0])|(6,[3],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|38.0| 28887.0|         0.0|         0.0|          50.0|   0.0|(2,[0],[1.0])|(9,[0],[1.0])| (16,[5],[1.0])| (7,[0],[1.0])| (15,[4],[1.0])|(6,[0],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "|43.0|292175.0|         0.0|         0.0|          45.0|   1.0|(2,[1],[1.0])|(9,[1],[1.0])| (16,[3],[1.0])| (7,[2],[1.0])| (15,[2],[1.0])|(6,[3],[1.0])|(5,[0],[1.0])| (42,[0],[1.0])|\n",
      "+----+--------+------------+------------+--------------+------+-------------+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data with Vector Assembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols=[\"age\",\"capital_gain\",\"capital_loss\",\"fnlwgt\",\"hours_per_week\",\"sex\",\"workclass\",\n",
    "            \"education\",\"marital_status\",\"occupation\",\"relationship\",\"native_country\",\"race\"]\n",
    "\n",
    "va = VectorAssembler(inputCols=input_cols, outputCol=\"features\").transform(dfhot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpoints = va.select(\"features\", \"income\").withColumnRenamed(\"income\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(107,[0,1,3,4,5,1...|  0.0|\n",
      "|(107,[0,3,4,5,8,1...|  0.0|\n",
      "|(107,[0,3,4,5,7,1...|  0.0|\n",
      "|(107,[0,3,4,5,7,2...|  0.0|\n",
      "|(107,[0,3,4,6,7,1...|  0.0|\n",
      "|(107,[0,3,4,6,7,1...|  0.0|\n",
      "|(107,[0,3,4,6,7,2...|  0.0|\n",
      "|(107,[0,3,4,5,8,1...|  1.0|\n",
      "|(107,[0,1,3,4,6,7...|  1.0|\n",
      "|(107,[0,1,3,4,5,7...|  1.0|\n",
      "|(107,[0,3,4,5,7,1...|  1.0|\n",
      "|(107,[0,3,4,5,11,...|  1.0|\n",
      "|(107,[0,3,4,6,7,1...|  0.0|\n",
      "|(107,[0,3,4,5,7,2...|  0.0|\n",
      "|(107,[0,3,4,5,7,2...|  1.0|\n",
      "|(107,[0,3,4,5,7,2...|  0.0|\n",
      "|(107,[0,3,4,5,8,1...|  0.0|\n",
      "|(107,[0,3,4,5,7,1...|  0.0|\n",
      "|(107,[0,3,4,5,7,2...|  0.0|\n",
      "|(107,[0,3,4,6,8,1...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/01 02:09:35 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "lpoints.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into training and vaildation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into training and vaildation sets.\n",
    "splits = lpoints.randomSplit([0.8, 0.2])\n",
    "adulttrain = splits[0].cache()\n",
    "adultvalid = splits[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpret the model parameters\n",
    "print(lrmodel.coefficients)\n",
    "print(lrmodel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate models using test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "rawPrediction : includes two values - log-odds that a sample doesn't and does belong to the category (making > 50,000).\n",
    "\n",
    "probability : the probability that the sample is not in the category.\n",
    "\n",
    "prediction : proability that the sample belongs to the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model. default metric : Area Under ROC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model. metric : Area Under PR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-fold validation and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
