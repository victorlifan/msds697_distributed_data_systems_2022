{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 16:55:57 WARN Utils: Your hostname, Fans-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.0.0.115 instead (on interface en0)\n",
      "22/03/06 16:55:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/06 16:55:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder,VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "\n",
    "#from user_definition import *\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "\n",
    "def toDoubleSafe(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except:\n",
    "        return str(v) #if it is not a float type return as a string.\n",
    "\n",
    "# def strip_time(x):\n",
    "#     x = x.strip(\"\\\"\")\n",
    "#     try:\n",
    "        \n",
    "#         return datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "#     except:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "penschema = StructType([\n",
    "    StructField(\"pix1\",DoubleType(),True),\n",
    "    StructField(\"pix2\",DoubleType(),True),\n",
    "    StructField(\"pix3\",DoubleType(),True),\n",
    "    StructField(\"pix4\",DoubleType(),True),\n",
    "    StructField(\"pix5\",DoubleType(),True),\n",
    "    StructField(\"pix6\",DoubleType(),True),\n",
    "    StructField(\"pix7\",DoubleType(),True),\n",
    "    StructField(\"pix8\",DoubleType(),True),\n",
    "    StructField(\"pix9\",DoubleType(),True),\n",
    "    StructField(\"pix10\",DoubleType(),True),\n",
    "    StructField(\"pix11\",DoubleType(),True),\n",
    "    StructField(\"pix12\",DoubleType(),True),\n",
    "    StructField(\"pix13\",DoubleType(),True),\n",
    "    StructField(\"pix14\",DoubleType(),True),\n",
    "    StructField(\"pix15\",DoubleType(),True),\n",
    "    StructField(\"pix16\",DoubleType(),True),\n",
    "    StructField(\"label\",DoubleType(),True)\n",
    "])\n",
    "\n",
    "dfpen = ss.read.csv(\"../Data/penbased.dat\", samplingRatio=0.3, schema=penschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "| pix1| pix2|pix3| pix4| pix5| pix6| pix7| pix8| pix9|pix10|pix11|pix12|pix13|pix14|pix15|pix16|label|\n",
      "+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "| 47.0|100.0|27.0| 81.0| 57.0| 37.0| 26.0|  0.0|  0.0| 23.0| 56.0| 53.0|100.0| 90.0| 40.0| 98.0|  8.0|\n",
      "|  0.0| 89.0|27.0|100.0| 42.0| 75.0| 29.0| 45.0| 15.0| 15.0| 37.0|  0.0| 69.0|  2.0|100.0|  6.0|  2.0|\n",
      "|  0.0| 57.0|31.0| 68.0| 72.0| 90.0|100.0|100.0| 76.0| 75.0| 50.0| 51.0| 28.0| 25.0| 16.0|  0.0|  1.0|\n",
      "|  0.0|100.0| 7.0| 92.0|  5.0| 68.0| 19.0| 45.0| 86.0| 34.0|100.0| 45.0| 74.0| 23.0| 67.0|  0.0|  4.0|\n",
      "|  0.0| 67.0|49.0| 83.0|100.0|100.0| 81.0| 80.0| 60.0| 60.0| 40.0| 40.0| 33.0| 20.0| 47.0|  0.0|  1.0|\n",
      "|100.0|100.0|88.0| 99.0| 49.0| 74.0| 17.0| 47.0|  0.0| 16.0| 37.0|  0.0| 73.0| 16.0| 20.0| 20.0|  6.0|\n",
      "|  0.0|100.0| 3.0| 72.0| 26.0| 35.0| 85.0| 35.0|100.0| 71.0| 73.0| 97.0| 65.0| 49.0| 66.0|  0.0|  4.0|\n",
      "|  0.0| 39.0| 2.0| 62.0| 11.0|  5.0| 63.0|  0.0|100.0| 43.0| 89.0| 99.0| 36.0|100.0|  0.0| 57.0|  0.0|\n",
      "| 13.0| 89.0|12.0| 50.0| 72.0| 38.0| 56.0|  0.0|  4.0| 17.0|  0.0| 61.0| 32.0| 94.0|100.0|100.0|  5.0|\n",
      "| 74.0| 87.0|31.0|100.0|  0.0| 69.0| 62.0| 64.0|100.0| 79.0|100.0| 38.0| 84.0|  0.0| 18.0|  1.0|  9.0|\n",
      "| 48.0| 96.0|62.0| 65.0| 88.0| 27.0| 21.0|  0.0| 21.0| 33.0| 79.0| 67.0|100.0|100.0|  0.0| 85.0|  8.0|\n",
      "|100.0|100.0|72.0| 99.0| 36.0| 78.0| 34.0| 54.0| 79.0| 47.0| 64.0| 13.0| 19.0|  0.0|  0.0|  2.0|  5.0|\n",
      "| 91.0| 74.0|54.0|100.0|  0.0| 87.0| 23.0| 59.0| 81.0| 67.0|100.0| 39.0| 79.0|  4.0| 21.0|  0.0|  9.0|\n",
      "|  0.0| 85.0|38.0|100.0| 81.0| 88.0| 87.0| 50.0| 84.0| 12.0| 58.0|  0.0| 53.0| 22.0|100.0| 24.0|  7.0|\n",
      "| 35.0| 76.0|57.0|100.0|100.0| 92.0| 68.0| 66.0| 81.0| 38.0| 82.0|  9.0| 32.0|  0.0|  0.0| 17.0|  3.0|\n",
      "| 50.0| 84.0|66.0|100.0| 75.0| 75.0| 51.0| 51.0|100.0| 42.0| 97.0| 13.0| 49.0|  0.0|  0.0|  7.0|  3.0|\n",
      "| 99.0| 80.0|63.0|100.0| 25.0| 76.0| 79.0| 68.0|100.0| 62.0| 97.0| 23.0| 54.0|  0.0|  0.0| 16.0|  9.0|\n",
      "| 24.0| 66.0|43.0|100.0| 59.0| 65.0| 34.0| 28.0|  0.0|  1.0| 16.0| 11.0| 58.0|  0.0|100.0|  1.0|  2.0|\n",
      "|  0.0| 73.0|19.0| 99.0| 72.0|100.0| 70.0| 73.0| 32.0| 48.0|  5.0| 18.0| 46.0|  0.0|100.0|  0.0|  2.0|\n",
      "| 12.0| 77.0|20.0| 62.0| 78.0| 40.0| 50.0|  0.0|  1.0| 17.0|  0.0| 64.0| 23.0| 98.0|100.0|100.0|  5.0|\n",
      "+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpen.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe with a feature vector and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vector_Assembler(df,y_column):\n",
    "    columns = df.columns\n",
    "    # remove y column\n",
    "    columns.remove(y_column)\n",
    "    va= VectorAssembler(inputCols=columns,outputCol='features').transform(df)\n",
    "    lpoints = va.select(\"features\", y_column).withColumnRenamed(y_column, \"label\")\n",
    "    return lpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpoints = Vector_Assembler(dfpen,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 16:58:15 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[47.0,100.0,27.0,...|  8.0|\n",
      "|[0.0,89.0,27.0,10...|  2.0|\n",
      "|[0.0,57.0,31.0,68...|  1.0|\n",
      "|[0.0,100.0,7.0,92...|  4.0|\n",
      "|[0.0,67.0,49.0,83...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpoints.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merging the data with Vector Assembler.\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "# va = VectorAssembler(outputCol=\"features\", inputCols=dfpen.columns[0:-1]) #except the last col."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataframe into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into training and vaildation sets.\n",
    "splits = lpoints.randomSplit([.8,.2])\n",
    "pendttrain = splits[0].cache()\n",
    "pendtvalid = splits[1].cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Training and Test data.\n",
    "# pendtsets = penlpoints.randomSplit([0.8, 0.2])\n",
    "# pendttrain = pendtsets[0].cache()\n",
    "# pendtvalid = pendtsets[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RandomForestClassifer and build a model using training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 17:03:32 WARN DAGScheduler: Broadcasting large task binary with size 1420.2 KiB\n",
      "22/03/06 17:03:32 WARN DAGScheduler: Broadcasting large task binary with size 1867.9 KiB\n",
      "22/03/06 17:03:33 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/03/06 17:03:33 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "22/03/06 17:03:33 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "22/03/06 17:03:34 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "22/03/06 17:03:34 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "22/03/06 17:03:34 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "22/03/06 17:03:34 WARN DAGScheduler: Broadcasting large task binary with size 1955.8 KiB\n",
      "22/03/06 17:03:34 WARN DAGScheduler: Broadcasting large task binary with size 1524.9 KiB\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "model = RandomForestClassifier(maxDepth=20)\n",
    "rfmodel = rf.fit(pendttrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpredicts = rfmodel.transform(pendtvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 17:03:39 WARN DAGScheduler: Broadcasting large task binary with size 1989.7 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9872581027730427"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expects two input columns: prediction and label.\n",
    "\n",
    "# f1|accuracy(defulat)|weightedPrecision|weightedRecall|weightedTruePositiveRate| \n",
    "# weightedFalsePositiveRate|weightedFMeasure|truePositiveRateByLabel| \n",
    "# falsePositiveRateByLabel|precisionByLabel|recallByLabel|fMeasureByLabel| \n",
    "# logLoss|hammingLoss\n",
    "metric_name = \"f1\"\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\\\n",
    "                .setLabelCol(\"label\")\\\n",
    "                .setPredictionCol(\"prediction\")\\\n",
    "                .setMetricName(metric_name) \n",
    "\n",
    "evaluator.evaluate(rfpredicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 17:03:52 WARN DAGScheduler: Broadcasting large task binary with size 1980.6 KiB\n",
      "22/03/06 17:03:53 WARN DAGScheduler: Broadcasting large task binary with size 1991.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrics = \n",
      "DenseMatrix([[201.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.],\n",
      "             [  0., 211.,  11.,   0.,   1.,   0.,   0.,   0.,   0.,   1.],\n",
      "             [  0.,   1., 212.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "             [  0.,   0.,   1., 184.,   1.,   1.,   0.,   0.,   0.,   0.],\n",
      "             [  1.,   0.,   0.,   0., 225.,   0.,   0.,   0.,   0.,   0.],\n",
      "             [  0.,   0.,   0.,   2.,   0., 195.,   0.,   0.,   0.,   1.],\n",
      "             [  0.,   0.,   0.,   0.,   0.,   0., 187.,   0.,   0.,   0.],\n",
      "             [  0.,   1.,   0.,   0.,   0.,   1.,   0., 205.,   0.,   0.],\n",
      "             [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   1., 181.,   0.],\n",
      "             [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 216.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "#prediction and label\n",
    "prediction_label = rfpredicts.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "metrics = MulticlassMetrics(prediction_label)\n",
    "\n",
    "confusionMetrics = metrics.confusionMatrix()\n",
    "\n",
    "print(\"Confusion Metrics = \\n%s\" % confusionMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanli/opt/anaconda3/envs/adv630/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "precision() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m prediction_label \u001b[38;5;241m=\u001b[39m rfpredicts\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrdd\n\u001b[1;32m      6\u001b[0m metrics \u001b[38;5;241m=\u001b[39m MulticlassMetrics(prediction_label)\n\u001b[0;32m----> 8\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mrecall()\n\u001b[1;32m     10\u001b[0m f1Score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mfMeasure()\n",
      "\u001b[0;31mTypeError\u001b[0m: precision() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "#prediction and label\n",
    "prediction_label = rfpredicts.select(\"prediction\", \"label\").rdd\n",
    "\n",
    "metrics = MulticlassMetrics(prediction_label)\n",
    "\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "confusionMetrics = metrics.confusionMatrix()\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "print(\"Confusion Metrics = \\n%s\" % confusionMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
